{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4T6QHHOnfcQ"
   },
   "source": [
    "# Part 1: Build CpG Detector\n",
    "\n",
    "Here we have a simple problem, given a DNA sequence (of N, A, C, G, T), count the number of CpGs in the sequence (consecutive CGs).\n",
    "\n",
    "We have defined a few helper functions / parameters for performing this task.\n",
    "\n",
    "We need you to build a LSTM model and train it to complish this task in PyTorch.\n",
    "\n",
    "A good solution will be a model that can be trained, with high confidence in correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mfS4cLmZD2oB"
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from functools import partial\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_f-brPAvKvTn"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE HERE\n",
    "def set_seed(seed=13):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(13)\n",
    "\n",
    "# Use this for getting x label\n",
    "def rand_sequence(n_seqs: int, seq_len: int=128) -> Sequence[int]:\n",
    "    for i in range(n_seqs):\n",
    "        yield [random.randint(0, 4) for _ in range(seq_len)]\n",
    "\n",
    "# Use this for getting y label\n",
    "def count_cpgs(seq: str) -> int:\n",
    "    cgs = 0\n",
    "    for i in range(0, len(seq) - 1):\n",
    "        dimer = seq[i:i+2]\n",
    "        # note that seq is a string, not a list\n",
    "        if dimer == \"CG\":\n",
    "            cgs += 1\n",
    "    return cgs\n",
    "\n",
    "# Alphabet helpers   \n",
    "alphabet = 'NACGT'\n",
    "dna2int = { a: i for a, i in zip(alphabet, range(5))}\n",
    "int2dna = { i: a for a, i in zip(alphabet, range(5))}\n",
    "\n",
    "intseq_to_dnaseq = partial(map, int2dna.get)\n",
    "dnaseq_to_intseq = partial(map, dna2int.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#equivalent of tensorflow categorical in torch\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1651686469847,
     "user": {
      "displayName": "Ylex",
      "userId": "01820639168093643789"
     },
     "user_tz": 240
    },
    "id": "VK9Qg5GHYxOb",
    "outputId": "0a00bbb6-d9ac-4cf8-ed84-b55b335d7f51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\susinghrawat\\AppData\\Local\\Temp\\ipykernel_36448\\1219703697.py:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  X_dna_seqs_train = torch.tensor(onehot_encodings, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "# we prepared two datasets for training and evaluation\n",
    "# training data scale we set to 2048\n",
    "# we test on 512\n",
    "\n",
    "def prepare_data(num_samples=100):\n",
    "    # prepared the training and test data\n",
    "    # you need to call rand_sequence and count_cpgs here to create the dataset\n",
    "    # step 1\n",
    "    X_dna_seqs_train = list(rand_sequence(num_samples))\n",
    "    \"\"\"\n",
    "    hint:\n",
    "        1. You can check X_dna_seqs_train by print, the data is ids which is your training X \n",
    "        2. You first convert ids back to DNA sequence\n",
    "        3. Then you run count_cpgs which will yield CGs counts - this will be the labels (Y)\n",
    "    \"\"\"\n",
    "    #step2\n",
    "    temp = [\"\".join(intseq_to_dnaseq(x)) for x in X_dna_seqs_train] # use intseq_to_dnaseq here to convert ids back to DNA seqs\n",
    "    #step3\n",
    "    y_dna_seqs = [count_cpgs(x) for x in temp] # use count_cpgs here to generate labels with temp generated in step2\n",
    "    #step4 \n",
    "    onehot_encodings = [to_categorical(x,num_classes=5) for x in X_dna_seqs_train] #create onehot encodings\n",
    "    #step5\n",
    "    X_dna_seqs_train = torch.tensor(onehot_encodings, dtype=torch.float)\n",
    "    y_dna_seqs = torch.tensor(y_dna_seqs, dtype=torch.float)\n",
    "    \n",
    "    return X_dna_seqs_train, y_dna_seqs\n",
    "    \n",
    "train_x, train_y = prepare_data(2048)\n",
    "test_x, test_y = prepare_data(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 128, 5])\n",
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some config\n",
    "LSTM_HIDDEN = 128\n",
    "LSTM_LAYER = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epoch_num = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# create data loader\n",
    "train_data_loader = DataLoader(TensorDataset(train_x, train_y), batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(TensorDataset(test_x, test_y), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q8fgxrM0LnLy"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class CpGPredictor(torch.nn.Module):\n",
    "    ''' Simple model that uses a LSTM to count the number of CpGs in a sequence '''\n",
    "    def __init__(self):\n",
    "        super(CpGPredictor, self).__init__()\n",
    "        # TODO complete model, you are free to add whatever layers you need here\n",
    "        # We do need a lstm and a classifier layer here but you are free to implement them in your way\n",
    "        self.lstm = torch.nn.LSTM(5, LSTM_HIDDEN, LSTM_LAYER, batch_first=True)\n",
    "        self.classifier = torch.nn.Linear(LSTM_HIDDEN, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO complete forward function\n",
    "        output, _ = self.lstm(x)\n",
    "        output = output[:, -1, :] #choosing last timestep from each batch\n",
    "        logits = self.classifier(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model / loss function / optimizer etc.\n",
    "model = CpGPredictor()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 584.6737458705902 Validation Loss: 4.6878204345703125\n",
      "Epoch: 10 Training Loss: 268.827424287796 Validation Loss: 3.4096262454986572\n",
      "Epoch: 20 Training Loss: 268.4294295310974 Validation Loss: 5.276222229003906\n",
      "Epoch: 30 Training Loss: 267.291357755661 Validation Loss: 4.4912848472595215\n",
      "Epoch: 40 Training Loss: 268.7998846769333 Validation Loss: 3.919861316680908\n",
      "Epoch: 50 Training Loss: 264.7804329395294 Validation Loss: 3.9704513549804688\n",
      "Epoch: 60 Training Loss: 261.8662860393524 Validation Loss: 3.3661792278289795\n",
      "Epoch: 70 Training Loss: 257.030246257782 Validation Loss: 4.0688066482543945\n",
      "Epoch: 80 Training Loss: 179.45953905582428 Validation Loss: 2.4652342796325684\n",
      "Epoch: 90 Training Loss: 8.03344694711268 Validation Loss: 0.1407589614391327\n",
      "Epoch: 100 Training Loss: 2.942875064909458 Validation Loss: 0.016522293910384178\n",
      "Epoch: 110 Training Loss: 2.528950863517821 Validation Loss: 0.016766704618930817\n",
      "Epoch: 120 Training Loss: 1.0915017542429268 Validation Loss: 0.016173839569091797\n",
      "Epoch: 130 Training Loss: 1.3928197119385004 Validation Loss: 0.018442494794726372\n",
      "Epoch: 140 Training Loss: 0.5464255618862808 Validation Loss: 0.00566824059933424\n",
      "Epoch: 150 Training Loss: 0.6287452164106071 Validation Loss: 0.006179420277476311\n",
      "Epoch: 160 Training Loss: 0.5546548068523407 Validation Loss: 0.006108874920755625\n",
      "Epoch: 170 Training Loss: 0.5387610115576535 Validation Loss: 0.0023076897487044334\n",
      "Epoch: 180 Training Loss: 1.4269087994471192 Validation Loss: 0.006598638836294413\n",
      "Epoch: 190 Training Loss: 0.7080204020021483 Validation Loss: 0.008345345966517925\n",
      "Epoch: 200 Training Loss: 1.038583398098126 Validation Loss: 0.005632874555885792\n",
      "Epoch: 210 Training Loss: 0.7060626887250692 Validation Loss: 0.002560802735388279\n",
      "Epoch: 220 Training Loss: 0.4276681466726586 Validation Loss: 0.011501643806695938\n",
      "Epoch: 230 Training Loss: 0.21298709028633311 Validation Loss: 0.0021251558791846037\n",
      "Epoch: 240 Training Loss: 0.7817825410747901 Validation Loss: 0.00692035723477602\n",
      "Epoch: 250 Training Loss: 0.3093506458681077 Validation Loss: 0.0024723908863961697\n",
      "Epoch: 260 Training Loss: 0.34639225131832063 Validation Loss: 0.004044973291456699\n",
      "Epoch: 270 Training Loss: 0.8026422376278788 Validation Loss: 0.0046410709619522095\n",
      "Epoch: 280 Training Loss: 0.18660138285486028 Validation Loss: 0.005237833596765995\n",
      "Epoch: 290 Training Loss: 0.13167079183040187 Validation Loss: 0.0022988393902778625\n"
     ]
    }
   ],
   "source": [
    "# training (you can modify the code below)\n",
    "t_loss = 0\n",
    "val_loss = 0\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "model.train()\n",
    "model.zero_grad()\n",
    "for i in range(epoch_num):\n",
    "    for batch in train_data_loader:\n",
    "        inp, target = batch\n",
    "        out = model(inp)\n",
    "        out = out.squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_loss += loss.item() \n",
    "    \n",
    "    if i%10==0:\n",
    "        #compute validation error\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(inp)\n",
    "            out = out.squeeze()\n",
    "            loss = loss_fn(out, target)\n",
    "            val_loss+=loss.item()\n",
    "\n",
    "        training_loss.append(t_loss)\n",
    "        validation_loss.append(val_loss)\n",
    "        print(\"Epoch:\",i,\"Training Loss:\",t_loss,\"Validation Loss:\",val_loss)\n",
    "        val_loss = 0\n",
    "    t_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, (ax1,ax2) = plt.subplots(2,1, layout='constrained')\n",
    "ax1.plot(training_loss)\n",
    "ax1.set_ylabel('train_loss')\n",
    "ax1.set_xlabel('epochs')\n",
    "ax2.plot(validation_loss)\n",
    "ax2.set_ylabel('val_loss')\n",
    "ax2.set_xlabel('epochs')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993852384097482\n"
     ]
    }
   ],
   "source": [
    "# eval (you can modify the code below)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model.eval()\n",
    "res_gs = []\n",
    "res_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        inp, target = batch\n",
    "        out = model(inp)\n",
    "        out = out.squeeze()\n",
    "        res_gs.extend(target.tolist())\n",
    "        res_pred.extend(out.tolist())\n",
    "print(r2_score(res_gs,res_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"trained_model/model_fixed_len_sequence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sample test\n",
    "# sample_input = \"NCACANNTNCGGAGGCGNA\"\n",
    "# seq = [x for x in dnaseq_to_intseq(sample_input)]\n",
    "# oneh = [to_categorical(x,num_classes=5) for x in seq]\n",
    "# sequence = torch.tensor(oneh, dtype=torch.float)\n",
    "# sequence = sequence.unsqueeze(0)\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     out = model(sequence)\n",
    "#     out = out.squeeze()\n",
    "#     print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMrRf_aVDRJm"
   },
   "source": [
    "# Part 2: what if the DNA sequences are not the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint we will need following imports\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AKvG-MNuXJr9"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE HERE\n",
    "random.seed(13)\n",
    "\n",
    "# Use this for getting x label\n",
    "def rand_sequence_var_len(n_seqs: int, lb: int=16, ub: int=128) -> Sequence[int]:\n",
    "    for i in range(n_seqs):\n",
    "        seq_len = random.randint(lb, ub)\n",
    "        yield [random.randint(1, 5) for _ in range(seq_len)]\n",
    "\n",
    "\n",
    "# Use this for getting y label\n",
    "def count_cpgs(seq: str) -> int:\n",
    "    cgs = 0\n",
    "    for i in range(0, len(seq) - 1):\n",
    "        dimer = seq[i:i+2]\n",
    "        # note that seq is a string, not a list\n",
    "        if dimer == \"CG\":\n",
    "            cgs += 1\n",
    "    return cgs\n",
    "\n",
    "\n",
    "# Alphabet helpers   \n",
    "alphabet = 'NACGT'\n",
    "dna2int = {a: i for a, i in zip(alphabet, range(1, 6))}\n",
    "int2dna = {i: a for a, i in zip(alphabet, range(1, 6))}\n",
    "dna2int.update({\"pad\": 0})\n",
    "int2dna.update({0: \"<pad>\"})\n",
    "\n",
    "intseq_to_dnaseq = partial(map, int2dna.get)\n",
    "dnaseq_to_intseq = partial(map, dna2int.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete the task based on the change\n",
    "def prepare_data(num_samples=100, min_len=16, max_len=128):\n",
    "    # TODO prepared the training and test data\n",
    "    # you need to call rand_sequence and count_cpgs here to create the dataset\n",
    "    #step 1\n",
    "    X_dna_seqs_train = list(rand_sequence_var_len(num_samples, min_len, max_len))\n",
    "    #step 2\n",
    "    temp = [\"\".join(intseq_to_dnaseq(x)) for x in X_dna_seqs_train]\n",
    "    #step3\n",
    "    y_dna_seqs = [count_cpgs(x) for x in temp]\n",
    "    #step4\n",
    "    X_dna_seqs_train = [torch.LongTensor(x) for x in X_dna_seqs_train]\n",
    "    X_dna_seqs_train_padding = pad_sequence(X_dna_seqs_train, batch_first=True, padding_value=dna2int['pad'])\n",
    "    #step5\n",
    "    X_dna_seqs_train_onehot_padding = [to_categorical(x,num_classes=6) for x in X_dna_seqs_train_padding] #create onehot encodings\n",
    "    X_dna_seqs_train_onehot_padding = torch.tensor(X_dna_seqs_train_onehot_padding, dtype=torch.float) \n",
    "    y_dna_seqs = torch.tensor(y_dna_seqs, dtype=torch.float)\n",
    "    \n",
    "    return X_dna_seqs_train_onehot_padding, y_dna_seqs\n",
    "    \n",
    "    \n",
    "min_len, max_len = 64, 128\n",
    "train_x, train_y = prepare_data(2048, min_len, max_len)\n",
    "test_x, test_y = prepare_data(512, min_len, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2048, 128, 6]), torch.Size([2048]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, lists, labels) -> None:\n",
    "        self.lists = lists\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.lists[index]), self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lists)\n",
    "\n",
    "# this will be a collate_fn for dataloader to pad sequence  \n",
    "#found the code from here --> https://www.codefull.org/2018/11/use-pytorchs-dataloader-with-variable-length-sequences-for-lstm-gru/\n",
    "class PadSequence:\n",
    "    def __call__(self, batch):\n",
    "        # Let's assume that each element in \"batch\" is a tuple (data, label).\n",
    "        # Sort the batch in the descending order\n",
    "        sorted_batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
    "        # Get each sequence and pad it\n",
    "        sequences = [x[0] for x in sorted_batch]\n",
    "        sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=dna2int['pad'])\n",
    "        # Also need to store the length of each sequence\n",
    "        # This is later needed in order to unpad the sequences\n",
    "        sequences_padded = torch.tensor(sequences_padded)\n",
    "        lengths = torch.tensor([len(x) for x in sequences])\n",
    "        # Don't forget to grab the labels of the *sorted* batch\n",
    "        labels = torch.tensor([x[1] for x in sorted_batch])\n",
    "        return sequences_padded, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some config\n",
    "LSTM_HIDDEN = 128\n",
    "LSTM_LAYER = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epoch_num = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# create data loader\n",
    "train_data_loader = DataLoader(MyDataset(train_x, train_y), batch_size=batch_size, collate_fn=PadSequence(), shuffle=True)\n",
    "test_data_loader = DataLoader(MyDataset(test_x, test_y), batch_size=batch_size, collate_fn=PadSequence(), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 6])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\susinghrawat\\AppData\\Local\\Temp\\ipykernel_36448\\674878220.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.lists[index]), self.labels[index]\n",
      "C:\\Users\\susinghrawat\\AppData\\Local\\Temp\\ipykernel_36448\\674878220.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequences_padded = torch.tensor(sequences_padded)\n"
     ]
    }
   ],
   "source": [
    "#check shapes of input\n",
    "for i in train_data_loader:\n",
    "    print(i[0].shape)\n",
    "    print(i[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class CpGPredictor(torch.nn.Module):\n",
    "    ''' Simple model that uses a LSTM to count the number of CpGs in a sequence '''\n",
    "    def __init__(self):\n",
    "        super(CpGPredictor, self).__init__()\n",
    "        # TODO complete model, you are free to add whatever layers you need here\n",
    "        # We do need a lstm and a classifier layer here but you are free to implement them in your way\n",
    "        self.lstm = torch.nn.LSTM(6, LSTM_HIDDEN, LSTM_LAYER, batch_first=True)\n",
    "        self.classifier = torch.nn.Linear(LSTM_HIDDEN, 1)\n",
    "\n",
    "    def forward(self, x, x_length):\n",
    "        ''' ChatGPT and google helped a lot in this one phew \n",
    "        (https://chat.openai.com/share/5aac1c10-60a4-4afb-ad6f-882e185969a2)\n",
    "        '''\n",
    "        # TODO complete forward function\n",
    "        x_pack = pack_padded_sequence(x,x_length, batch_first=True, enforce_sorted=True)\n",
    "        x_padded, _ = pad_packed_sequence(x_pack, batch_first=True)\n",
    "        output, _ = self.lstm(x_padded)\n",
    "        output = output[:, -1, :] #choosing last timestep from each batch\n",
    "        logits = self.classifier(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model / loss function / optimizer etc.\n",
    "model = CpGPredictor()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\susinghrawat\\AppData\\Local\\Temp\\ipykernel_36448\\674878220.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.lists[index]), self.labels[index]\n",
      "C:\\Users\\susinghrawat\\AppData\\Local\\Temp\\ipykernel_36448\\674878220.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequences_padded = torch.tensor(sequences_padded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 416.2323350906372 Validation Loss: 3.8909389972686768\n",
      "Epoch: 10 Training Loss: 234.6464604139328 Validation Loss: 1.8835800886154175\n",
      "Epoch: 20 Training Loss: 206.66390240192413 Validation Loss: 2.9316611289978027\n",
      "Epoch: 30 Training Loss: 191.4844170808792 Validation Loss: 2.812187433242798\n",
      "Epoch: 40 Training Loss: 15.919064499437809 Validation Loss: 0.1751340925693512\n",
      "Epoch: 50 Training Loss: 2.7332090493291616 Validation Loss: 0.03850292041897774\n",
      "Epoch: 60 Training Loss: 2.150206350721419 Validation Loss: 0.007447096984833479\n",
      "Epoch: 70 Training Loss: 0.8967099077999592 Validation Loss: 0.009058049879968166\n",
      "Epoch: 80 Training Loss: 1.328771028202027 Validation Loss: 0.018567301332950592\n",
      "Epoch: 90 Training Loss: 1.001737529411912 Validation Loss: 0.03285231441259384\n",
      "Epoch: 100 Training Loss: 1.2525408025830984 Validation Loss: 0.008755188435316086\n",
      "Epoch: 110 Training Loss: 1.0542867635376751 Validation Loss: 0.012112352065742016\n",
      "Epoch: 120 Training Loss: 0.34295085188932717 Validation Loss: 0.006668528541922569\n",
      "Epoch: 130 Training Loss: 0.427964354516007 Validation Loss: 0.007214022800326347\n",
      "Epoch: 140 Training Loss: 0.2784820814849809 Validation Loss: 0.002301677130162716\n",
      "Epoch: 150 Training Loss: 0.2599013119470328 Validation Loss: 0.00499682268127799\n",
      "Epoch: 160 Training Loss: 0.8364005216863006 Validation Loss: 0.004288367927074432\n",
      "Epoch: 170 Training Loss: 0.1917195882415399 Validation Loss: 0.0021603875793516636\n",
      "Epoch: 180 Training Loss: 0.8764848137507215 Validation Loss: 0.006655265111476183\n",
      "Epoch: 190 Training Loss: 0.22979922412196174 Validation Loss: 0.0035095501225441694\n",
      "Epoch: 200 Training Loss: 0.12133619468659163 Validation Loss: 0.001173539785668254\n",
      "Epoch: 210 Training Loss: 0.1121081109449733 Validation Loss: 0.0018155932193621993\n",
      "Epoch: 220 Training Loss: 0.23199807212222368 Validation Loss: 0.0035035472828894854\n",
      "Epoch: 230 Training Loss: 0.07869396884052549 Validation Loss: 0.0003724831622093916\n",
      "Epoch: 240 Training Loss: 0.3004704450140707 Validation Loss: 0.00351079273968935\n",
      "Epoch: 250 Training Loss: 0.038785715063568205 Validation Loss: 0.0004406892112456262\n",
      "Epoch: 260 Training Loss: 0.08509467565454543 Validation Loss: 0.00038537936052307487\n",
      "Epoch: 270 Training Loss: 0.09947838756488636 Validation Loss: 0.0026145491283386946\n",
      "Epoch: 280 Training Loss: 0.2164325324993115 Validation Loss: 0.0011533311335369945\n",
      "Epoch: 290 Training Loss: 0.1351853671076242 Validation Loss: 0.009850372560322285\n"
     ]
    }
   ],
   "source": [
    "# training (you can modify the code below)\n",
    "t_loss = 0\n",
    "val_loss = 0\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "model.train()\n",
    "model.zero_grad()\n",
    "for i in range(epoch_num):\n",
    "    for batch in train_data_loader:\n",
    "        inp, length, target = batch\n",
    "        out = model(inp,length)\n",
    "        out = out.squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_loss += loss.item() \n",
    "    \n",
    "    if i%10==0:\n",
    "        #compute validation error\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(inp, length)\n",
    "            out = out.squeeze()\n",
    "            loss = loss_fn(out, target)\n",
    "            val_loss+=loss.item()\n",
    "    \n",
    "        training_loss.append(t_loss)\n",
    "        validation_loss.append(val_loss)\n",
    "        print(\"Epoch:\",i,\"Training Loss:\",t_loss,\"Validation Loss:\",val_loss)\n",
    "        val_loss = 0\n",
    "    t_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995178676873524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\susinghrawat\\AppData\\Local\\Temp\\ipykernel_36448\\674878220.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.lists[index]), self.labels[index]\n",
      "C:\\Users\\susinghrawat\\AppData\\Local\\Temp\\ipykernel_36448\\674878220.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequences_padded = torch.tensor(sequences_padded)\n"
     ]
    }
   ],
   "source": [
    "# eval (you can modify the code below)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model.eval()\n",
    "res_gs = []\n",
    "res_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        inp, length, target = batch\n",
    "        out = model(inp, length)\n",
    "        out = out.squeeze()\n",
    "        res_gs.extend(target.tolist())\n",
    "        res_pred.extend(out.tolist())\n",
    "print(r2_score(res_gs,res_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"trained_model/model_variable_len_sequence.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_seq_to_desired_padding(sequence, desired_length=128):\n",
    "    pad_right = desired_length - len(sequence)\n",
    "    sequence.extend([dna2int[\"pad\"]]*pad_right)\n",
    "    return sequence\n",
    "\n",
    "def inference_for_single_sequence(sequence, maxlen):\n",
    "    X_dna_seqs = sequence\n",
    "    temp = [\"\".join(intseq_to_dnaseq(x)) for x in X_dna_seqs]\n",
    "    y_dna_seqs = [count_cpgs(x) for x in temp]\n",
    "    X_dna_seqs_padding = [convert_seq_to_desired_padding(x, desired_length=maxlen) for x in X_dna_seqs]\n",
    "    X_dna_seqs_onehot_padding = [to_categorical(x,num_classes=6) for x in X_dna_seqs_padding] \n",
    "    X_dna_seqs_onehot_padding = torch.tensor(X_dna_seqs_onehot_padding, dtype=torch.float) \n",
    "    y_dna_seqs = torch.tensor(y_dna_seqs, dtype=torch.float)\n",
    "    \n",
    "    return X_dna_seqs_onehot_padding, y_dna_seqs\n",
    "\n",
    "\n",
    "def evaluation_for_single_sequence(dna_seq: str):\n",
    "    seq = [[x for x in dnaseq_to_intseq(dna_seq)]]\n",
    "    sample_x, sample_y = inference_for_single_sequence(seq, 128)\n",
    "    dl = DataLoader(MyDataset(sample_x,sample_y), batch_size=1, collate_fn=PadSequence())\n",
    "    \n",
    "    model.eval()\n",
    "    res_gs = []\n",
    "    res_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            inp, length, target = batch\n",
    "            out = model(inp, length)\n",
    "            out = out.squeeze()\n",
    "            return out.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\susinghrawat\\AppData\\Local\\Temp\\ipykernel_36448\\674878220.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.lists[index]), self.labels[index]\n",
      "C:\\Users\\susinghrawat\\AppData\\Local\\Temp\\ipykernel_36448\\674878220.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequences_padded = torch.tensor(sequences_padded)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0529332160949707"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_for_single_sequence(dna_seq= \"NCACANNTNCGGAGGCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Xi Yangs Copy of broken-nn-template.ipynb",
   "provenance": [
    {
     "file_id": "13GlbI_pdKNES8I718iwl1KNnMZ73iOOn",
     "timestamp": 1651680757732
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
